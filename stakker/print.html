<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js rust">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Stakker actor runtime guide</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="A guide to the Stakker low-level actor runtime for Rust">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "rust";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item affix "><a href="about.html">About Stakker</a></li><li class="chapter-item "><a href="faq.html"><strong aria-hidden="true">1.</strong> Stakker FAQ</a></li><li class="chapter-item "><a href="d-intro.html"><strong aria-hidden="true">2.</strong> Stakker Design Notes</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="d-origin.html"><strong aria-hidden="true">2.1.</strong> Origin</a></li><li class="chapter-item "><a href="d-addr.html"><strong aria-hidden="true">2.2.</strong> Addressing events to objects</a></li><li class="chapter-item "><a href="d-deliv.html"><strong aria-hidden="true">2.3.</strong> Delivering events</a></li><li class="chapter-item "><a href="d-actor.html"><strong aria-hidden="true">2.4.</strong> Becoming an actor system</a></li><li class="chapter-item "><a href="d-guarantee.html"><strong aria-hidden="true">2.5.</strong> Actor guarantees</a></li><li class="chapter-item "><a href="d-lowlev.html"><strong aria-hidden="true">2.6.</strong> Low-level actors</a></li><li class="chapter-item "><a href="d-fast.html"><strong aria-hidden="true">2.7.</strong> Fast message execution</a></li><li class="chapter-item "><a href="d-queue.html"><strong aria-hidden="true">2.8.</strong> Queue execution behaviour</a></li><li class="chapter-item "><a href="d-time.html"><strong aria-hidden="true">2.9.</strong> Time virtualization</a></li><li class="chapter-item "><a href="d-events.html"><strong aria-hidden="true">2.10.</strong> Event source independence</a></li><li class="chapter-item "><a href="d-single.html"><strong aria-hidden="true">2.11.</strong> Single-threaded performance</a></li><li class="chapter-item "><a href="d-whysing.html"><strong aria-hidden="true">2.12.</strong> Why single-threaded?</a></li><li class="chapter-item "><a href="d-timers.html"><strong aria-hidden="true">2.13.</strong> Timer queue</a></li><li class="chapter-item "><a href="d-defer.html"><strong aria-hidden="true">2.14.</strong> Deferrer</a></li><li class="chapter-item "><a href="d-prep.html"><strong aria-hidden="true">2.15.</strong> Actor Prep state</a></li><li class="chapter-item "><a href="d-sig.html"><strong aria-hidden="true">2.16.</strong> Signatures of actor methods</a></li><li class="chapter-item "><a href="d-sigalt.html"><strong aria-hidden="true">2.17.</strong> Alternative signatures</a></li><li class="chapter-item "><a href="d-data.html"><strong aria-hidden="true">2.18.</strong> Data kept with actor state</a></li><li class="chapter-item "><a href="d-overh.html"><strong aria-hidden="true">2.19.</strong> Overhead of an actor</a></li><li class="chapter-item "><a href="d-macro.html"><strong aria-hidden="true">2.20.</strong> Macro argument structure</a></li><li class="chapter-item "><a href="d-drop.html"><strong aria-hidden="true">2.21.</strong> Dropping to clean up</a></li><li class="chapter-item "><a href="d-feat.html"><strong aria-hidden="true">2.22.</strong> Cargo features and safety</a></li><li class="chapter-item "><a href="d-whyactor.html"><strong aria-hidden="true">2.23.</strong> Why use actors?</a></li></ol></li><li class="chapter-item "><a href="g-intro.html"><strong aria-hidden="true">3.</strong> Stakker Guide</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="g-ecosys.html"><strong aria-hidden="true">3.1.</strong> Finding Stakker-compatible crates</a></li><li class="chapter-item "><a href="g-retfwd.html"><strong aria-hidden="true">3.2.</strong> Ret and Fwd differences</a></li><li class="chapter-item "><a href="g-retnone.html"><strong aria-hidden="true">3.3.</strong> Detecting delivery failure</a></li><li class="chapter-item "><a href="g-term.html"><strong aria-hidden="true">3.4.</strong> Actor termination</a></li><li class="chapter-item "><a href="g-traits.html"><strong aria-hidden="true">3.5.</strong> Actor&lt;dyn Trait&gt;</a></li><li class="chapter-item "><a href="g-toplevel.html"><strong aria-hidden="true">3.6.</strong> Top-level actor template</a></li><li class="chapter-item "><a href="g-waker.html"><strong aria-hidden="true">3.7.</strong> Inter-thread communication</a></li></ol></li><li class="chapter-item "><a href="roadmap.html"><strong aria-hidden="true">4.</strong> Stakker Roadmap</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Stakker actor runtime guide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#about-stakker" id="about-stakker">About Stakker</a></h1>
<p><strong>Stakker</strong> is a lightweight low-level single-threaded actor runtime
for Rust.  Some features:</p>
<ul>
<li>It is designed to be layered on top of whatever event loop the user
prefers to use, including ones from other languages.</li>
<li>Asynchronous calls are addressed directly to individual methods
within an actor, rather like Pony behaviours.</li>
<li>All calls and argument types are known and statically checked at
compile-time, which is very efficient and gives the optimiser a lot
of scope.</li>
<li>It provides a timer queue for timeouts or delayed calls, a lazy
queue to allow batching recent operations, and an idle queue for
running a call when nothing else is outstanding.</li>
<li>Uses <code>unsafe</code> by default for added efficiency at runtime.  However,
enabling the &quot;no-unsafe&quot; cargo feature switches to a fully safe
implementation, and builds with <code>#[forbid(unsafe_code)]</code> to
guarantee that no unsafe code is present.</li>
</ul>
<p><strong>Resources:</strong></p>
<ul>
<li><a href="https://github.com/uazu/stakker"><strong>Stakker</strong> GitHub page</a></li>
<li><a href="https://docs.rs/stakker">Documentation on <strong>docs.rs</strong></a></li>
<li><a href="https://crates.io/crates/stakker">Crate on <strong>crates.io</strong></a></li>
</ul>
<p>Questions not covered in the FAQ can be asked in the <a href="https://github.com/uazu/stakker/discussions">GitHub
discussion area</a>.  Please
raise bugs and other issues on the <a href="https://github.com/uazu/stakker/issues">GitHub issues
page</a>.</p>
<p>In future if more people come to use <strong>Stakker</strong>, it would be good to
have some means of notifying those people if new features are being
considered, to include them in discussions.  This could be a
forever-open GitHub issue, or some other low-tech channel.  I'm open
to suggestions if someone has done this before.</p>
<p><strong>Related crates:</strong></p>
<ul>
<li><a href="https://crates.io/crates/stakker_mio"><strong>stakker_mio</strong></a></li>
<li><a href="https://crates.io/crates/stakker_macros"><strong>stakker_macros</strong></a></li>
<li><a href="https://crates.io/crates/stakker_tui"><strong>stakker_tui</strong></a></li>
<li><a href="https://crates.io/crates/stakker_log"><strong>stakker_log</strong></a></li>
<li><a href="https://crates.io/crates/qcell"><strong>qcell</strong></a></li>
</ul>
<p>Let me know if you have a crate you'd like added here.</p>
<h1><a class="header" href="#stakker-faq" id="stakker-faq">Stakker FAQ</a></h1>
<p>To submit a question, please raise an issue on the <a href="https://github.com/uazu/stakker/issues">Stakker GitHub
page</a>.</p>
<h2><a class="header" href="#the-cargo-features-seem-confusing--which-ones-do-i-need" id="the-cargo-features-seem-confusing--which-ones-do-i-need">The cargo features seem confusing.  Which ones do I need?</a></h2>
<p>Remember that changing the cargo features does not change the API of
the <strong>Stakker</strong> crate.  Rather the features change the implementations
that back the API, to support different ways of using <strong>Stakker</strong>.  If
you are only using a single <strong>Stakker</strong> instance in your app, the
default features will be fine.  If you plan to run more than one
instance, then check the features documentation on the front page of
the <strong>Stakker</strong> rustdoc on <code>docs.rs</code>, or else you'll get a panic.</p>
<h2><a class="header" href="#how-can-i-create-an-actorowndyn-trait-and-call-it" id="how-can-i-create-an-actorowndyn-trait-and-call-it">How can I create an <code>ActorOwn&lt;dyn Trait&gt;</code> and call it?</a></h2>
<p>See the <a href="https://docs.rs/stakker/*/stakker/macro.actor_of_trait.html"><code>actor_of_trait!</code></a> macro for details of the best current
solution, and the <a href="d-traits.html">Traits Design Notes</a> for alternative
solutions and the reasons why <code>Actor&lt;dyn Traits&gt;</code> is not possible
right now.</p>
<h1><a class="header" href="#stakker-design-notes" id="stakker-design-notes">Stakker Design Notes</a></h1>
<p>This section explains the reasoning behind some of the design choices
of the <strong>Stakker</strong> crate.</p>
<h1><a class="header" href="#origin" id="origin">Origin</a></h1>
<p>The <strong>Stakker</strong> crate didn't start out as an actor library.  Rather it
started out as an exploration of how to deliver events to the correct
contexts for them to be handled, and doing that in a way that is fully
compatible with &quot;the Rust way&quot;, i.e. that takes full advantage of
Rust's approach to borrowing and ownership.</p>
<p>So effectively this is a low-level actor crate that evolved directly
and organically from Rust's fundamental principles, from the ground
up.</p>
<h1><a class="header" href="#addressing-events-to-objects" id="addressing-events-to-objects">Addressing events to objects</a></h1>
<p>The most natural way to organize objects or components in core Rust is
in tree-like graphs with single ownership and no cross-references or
back-references within the tree.  However to manage an event system,
events must be delivered to specific objects or components.  So some
form of references to those objects are required to support the event
system.</p>
<p>In Rust's standard library, multiple ownership or long-lived direct
references within a heterogeneous set of objects means using <a href="https://doc.rust-lang.org/stable/std/rc/struct.Rc.html"><code>Rc</code></a>.
However this also means giving up compile-time borrowing checks and
reverting to <a href="https://doc.rust-lang.org/stable/std/cell/struct.RefCell.html"><code>RefCell</code></a>, which does run-time checks instead.
Immediately we've lost one of Rust's most important compile-time
checks.  Investigating how to regain this compile-time check resulted
in the <a href="https://crates.io/crates/qcell"><strong>qcell</strong></a> crate, which re-enables zero-cost compile-time
checks of ownership behind <a href="https://doc.rust-lang.org/stable/std/rc/struct.Rc.html"><code>Rc</code></a> references.</p>
<p>So this means that we can now have both <a href="https://doc.rust-lang.org/stable/std/rc/struct.Rc.html"><code>Rc</code></a> references and safe
mutable access to the <a href="https://doc.rust-lang.org/stable/std/rc/struct.Rc.html"><code>Rc</code></a> contents without any run-time checks or
run-time cost.</p>
<h1><a class="header" href="#delivering-events" id="delivering-events">Delivering events</a></h1>
<p>The next problem is how to deliver events.  One approach is to deliver
an event to the destination as soon as it occurs, as a direct method
call.  However this results in nested callbacks on the stack, i.e. one
event causes an event handler to be called on another object, which in
responding to that event causes other events to be generated, calling
event handlers in other objects, all before the original event handler
has completed.  The main problem with this approach is that it can
lead to re-entrant calls to the same object, which in other languages
can result in very hard to understand bugs.</p>
<p>However in Rust there is a bigger problem, because a re-entrant call
will require borrowing the same object twice.  If we use <a href="https://doc.rust-lang.org/stable/std/cell/struct.RefCell.html"><code>RefCell</code></a>,
we'll only discover this bug if we're lucky enough to come across it
in testing.  However if we use <a href="https://crates.io/crates/qcell"><strong>qcell</strong></a> instead, there is
absolutely no way to construct a program that will execute a
re-entrant call on an object.  So letting Rust do compile-time
borrowing checks on data behind <a href="https://doc.rust-lang.org/stable/std/rc/struct.Rc.html"><code>Rc</code></a> pays off, because it forces us
to adopt a design that has none of the problems that are easy to
produce in other languages accidentally.</p>
<p>So to avoid borrowing problems and re-entrant calls, event sending and
event delivery must be separated, which means that a queue is
necessary.  The most fundamental queue would be one that stores a list
of <a href="https://doc.rust-lang.org/stable/std/ops/trait.FnOnce.html"><code>FnOnce</code></a> closures to execute later.  It's possible to make this
efficient by storing the closures in a flat <code>Vec&lt;u8&gt;</code>, which means
that no allocations are required to send a message, so long as the
queue buffer has grown big enough.</p>
<p>This also demonstrates another pattern in Rust, that Rust's rules seem
to lead to shallow call-stacks.  This is because when a borrow is
active, that often restricts access to other things.  To get access to
those things again means dropping back down the stack again.  Also
when borrows are passed deeper and deeper into the code, they seem to
become more and more invasive and restrictive, as you end up having to
annotate more and more functions and structures with lifetimes.</p>
<p>Using a <a href="https://doc.rust-lang.org/stable/std/ops/trait.FnOnce.html"><code>FnOnce</code></a> queue to defer operations untangles all of this and
means that each operation is run directly from the main loop with the
minimum restrictions from the borrow checker.</p>
<h1><a class="header" href="#becoming-an-actor-system" id="becoming-an-actor-system">Becoming an actor system</a></h1>
<p>So at this point we have:</p>
<ul>
<li>
<p>Components which can be addressed from anywhere, with ref-counting
references to them</p>
</li>
<li>
<p>No access to component state and no possibility to make direct calls
to a component from another component, all guaranteed by the borrow
checker</p>
</li>
<li>
<p>A queue that allows calls to methods on other components to be
deferred to run later</p>
</li>
</ul>
<p>This is so close to an actor system, that we might as well formalize
it as one to make it easier to reason about.</p>
<p>However, compared to other actor systems, there are no per-actor
message queues, and the 'messages' are actually <a href="https://doc.rust-lang.org/stable/std/ops/trait.FnOnce.html"><code>FnOnce</code></a> closures
which call a method directly on the actor, rather than some arbitrary
message structure that needs to be interpreted.  So it is much closer
to actors as provided by the Pony language, rather than some classical
actor system where all the messages are visible and dealt with by
hand.</p>
<p>Effectively each actor method on a <strong>Stakker</strong> actor takes the role of
a message type, and the arguments of that method take the role of the
data of that message.</p>
<h1><a class="header" href="#actor-guarantees" id="actor-guarantees">Actor guarantees</a></h1>
<p><strong>Stakker</strong> is not a 100% strict actor system.  Due to Rust's interior
mutability (e.g. <code>Rc&lt;Cell&gt;</code>, <code>Rc&lt;RefCell&gt;</code>, <code>Arc&lt;Mutex&gt;</code>, etc), it is
hard to totally forbid shared mutable state between actors.  Also
there are cases when shared mutable state may be useful for
performance reasons.  So <strong>Stakker</strong> accepts the existence of shared
mutable state and also offers the <a href="https://docs.rs/stakker/*/stakker/struct.Share.html"><code>Share</code></a> type which provides
zero-cost compile-time-borrow-checked shared mutable data between
actors.</p>
<p>Sharing mutable state breaks the actor model and so must be used with
care (if used at all), as it might complicate the coder's ability to
reason cleanly about their code.  The danger is about the same as
using IPC shared memory between processes, or shared buffers between
threads.  However there are no locking concerns as Rust's borrow
checker ensures that the coder has exclusive access whilst they hold a
mutable reference to shared state.</p>
<p>The external interface of a group of actors bound together by shared
mutable data still follows the actor model.  So whilst the actor model
is broken within the group, the larger system is still easy to reason
about.  It's only necessary to take care about interactions within
that group.</p>
<p>So this means that it's possible to break up a single actor into many
smaller actors where it is cleaner in the code to receive events
directly to those actors, and yet they may still work together using
shared mutable state if necessary for efficiency reasons.</p>
<p>Remember that the purpose of actors in <strong>Stakker</strong> is only to provide
a context that is capable of receiving events.  You can create complex
trees and tables of logical components within a single actor, and that
is fine.  Not everything needs to be an actor.  However as soon as an
individual component needs to receive and handle events itself
(including timers), it's likely that the code will be simplified by
splitting it out as a separate actor.  The cost of doing so in
<strong>Stakker</strong> is small.</p>
<p>Making <strong>Stakker</strong> an actor system by default means that most of the
code is easy to reason about locally, but those parts that need some
extra performance through shared mutable state can still be written
efficiently.</p>
<p>So, in <strong>Stakker</strong>:</p>
<ul>
<li>
<p>Rust's guarantees <em>always</em> apply</p>
</li>
<li>
<p>The actor-model guarantees <em>always</em> apply regarding forbidding
access to another actor's state or methods.  (Not even interior
mutability can break this.)</p>
</li>
<li>
<p>But the actor-model assumption of no shared mutable state only
applies by default, until the coder intentionally passes sharable
data between two actors.</p>
</li>
</ul>
<h1><a class="header" href="#low-level-not-medium--or-high-level" id="low-level-not-medium--or-high-level"><em>Low-level</em>, not medium- or high-level</a></h1>
<p>The aim is that the cost of a deferred inter-actor call should be on
the order of a normal direct inter-object call.  Obviously we can
never as low as a direct call, but we want to get as close as
possible.  This means that <strong>Stakker</strong> is not aiming to replace
multi-threaded asynchronous runtimes, multi-threaded asynchronous
message systems, inter-thread channels, distributed systems, or
anything else like that.</p>
<p>Rather <strong>Stakker</strong>'s aim is to replace a mess of <code>Rc&lt;RefCell&lt;...&gt;&gt;</code>
and a tangle of direct and indirect inter-object calls (or any other
improvised collection of communicating components in the same thread)
with a nice ordered, well-behaved set of actors, easy to reason about
and maintain.</p>
<p>Higher-level inter-thread load balancing, work distribution and
message passing can be layered on top of <strong>Stakker</strong> as necessary.</p>
<h1><a class="header" href="#fast-message-execution" id="fast-message-execution">Fast message execution</a></h1>
<p>When an actor call is deferred to the <a href="https://doc.rust-lang.org/stable/std/ops/trait.FnOnce.html"><code>FnOnce</code></a> queue, for example
with the <a href="https://docs.rs/stakker/*/stakker/macro.call.html"><code>call!</code></a> macro, the type and target method and any constant
arguments are fully known to the Rust compiler.  The only variables
are the target actor's address and the remaining arguments.  Rust can
inline and optimise this closure, effectively specializing it to the
type and method and the constant arguments provided.  So this means
that the closure might never even branch to the actor's code, since
that might all have been inlined and optimised down.  So the queue can
execute much faster than any kind of traditional actor messaging
system.  The call effectively bypasses all the message creation and
interpretation, and directly calls (or inlines) the actual actor code
that needs to be run.</p>
<p>Similarly, where an arbitrary callback is required (using <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> or
<a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a>), for example where the type of the target actor is not known
to the calling actor, this is handled as two closures.  The first
closure accepts the arguments in the <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> signature, and pushes the
second closure to the <a href="https://doc.rust-lang.org/stable/std/ops/trait.FnOnce.html"><code>FnOnce</code></a> queue.  The second closure is just
like a normal <a href="https://docs.rs/stakker/*/stakker/macro.call.html"><code>call!</code></a>, so can be fully optimised down to a specific
type and method.  The first closure is just some glue that assembles
the variable arguments ready for the second closure.  So again, this
is as direct as you can get, with no superfluous activity.</p>
<p>So again, aligning with Rust's strengths and making full use of Rust's
compile-time checks and compile-time knowledge pays off.</p>
<h1><a class="header" href="#queue-execution-behaviour" id="queue-execution-behaviour">Queue execution behaviour</a></h1>
<p>The normal pattern is to introduce one or more events into the system
as actor calls pushed onto the main queue, and then to run the queue
to completion.  This means that the queue is run repeatedly until it
is empty.  You can imagine that a queued call to the actor may trigger
other calls as a consequence, and those might cause other calls, but
eventually all the necessary changes will finish propagating through
the system of actors, and then things will go quiet again.</p>
<p><strong>Stakker</strong> always runs the main queue to completion before doing
anything else.  This means that if you wish to avoid saturating the
CPU, it's necessary to regulate fetching input data or accepting input
events.  Load regulation does not occur within the actor system.</p>
<p>To aid with this, two additional queues are provided:</p>
<ul>
<li>
<p>The first is the &quot;lazy&quot; queue.  This is run when the main queue is
fully exhausted, but before checking for new I/O events.  As an
example, it can be used to help batch output together into a single
big flush.  For example when writing to TCP, executing the main
queue might mean several chunks of data being written to a stream's
output buffer.  Flushing after each write would be inefficient, and
flushing after a delay would be too slow.  Instead an actor can put
the flush call on the lazy queue, and do one big flush once the
current batch of processing is complete.</p>
</li>
<li>
<p>The second is the &quot;idle&quot; queue.  This is executed only when the
thread becomes idle, i.e. the main and lazy queues are empty and
there are no new external events that need handling.  This may be
used to apply back-pressure on an incoming stream, by fetching more
data only when there is nothing else to do.  When there are several
items on the idle queue, they will execute in a round-robin fashion,
assuming each call pushes a new call back onto the queue when it
executes.</p>
</li>
</ul>
<h1><a class="header" href="#time-virtualization" id="time-virtualization">Time virtualization</a></h1>
<p>Actors should use <code>cx.now()</code> to get the current <code>Instant</code>.  The
current time is provided to <strong>Stakker</strong> by the external code that is
running the event loop.</p>
<p>This has several consequences.  For one, a batch of processing will
all occur at the same logical time.  Another is that the overhead of
constantly calling <code>Instant::now()</code> throughout the code is avoided.
(<code>Instant::now()</code> uses a <code>Mutex</code> on some platforms.)  In addition,
when it's necessary to integrate <strong>Stakker</strong> into non-Rust code, the
current time from that code can be used instead of Rust's idea of
time.</p>
<p>However a more interesting aspect of this is that it allows time to be
virtualized.  So you can make time appear to go faster or slower than
realtime.  You can skip over long sleeps when testing your
application, or trigger timeouts when testing an individual actor,
without consuming real time to do so.  If you have a suitable external
tool communicating with your main loop, you can coordinate a group of
processes to skip over common sleeps to accelerate any testing that
isn't CPU-bound.  The <strong>Stakker</strong> runtime and the application won't
know the difference.</p>
<h1><a class="header" href="#event-source-independence" id="event-source-independence">Event source independence</a></h1>
<p>The core actor runtime crate of <strong>Stakker</strong> has no dependency on any
event system.  An interface to <strong>mio</strong> is provided as the
<a href="https://crates.io/crates/stakker_mio"><strong>stakker_mio</strong></a> crate, but it should be possible to integrate
<strong>Stakker</strong> into any event system, even ones written in other
languages.</p>
<p>All that <strong>Stakker</strong> requires is that the external event system
provides it with one timeout (to wake it when the next <strong>Stakker</strong>
timer expires), and that it delivers events to it as calls pushed onto
the <strong>Stakker</strong> queue.</p>
<h1><a class="header" href="#maximised-single-threaded-performance" id="maximised-single-threaded-performance">Maximised single-threaded performance</a></h1>
<p>Each <strong>Stakker</strong> instance is oriented around running as fast as
possible within its own thread, avoiding any synchronization
completely unless specifically requested.  So a single <strong>Stakker</strong>
instance and all of its associated actors are intentionally limited to
running on a single thread.  Unless something uses a <a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a>, there
should be no code in <strong>Stakker</strong> that will cause execution of any kind
of a CPU memory fence or other synchronization primitive.  So the CPU
core can run at full speed.</p>
<p>This means that inter-actor calls can be very fast.  With the default
features, making or executing an actor call does not require a memory
allocation.  A closure is added to the end of a queue stored in a flat
preallocated buffer, and is then later executed straight out of that
buffer.  The average call cost varies by load, but overall it is
roughly similar to calling things through <code>Rc&lt;RefCell&gt;</code>, once code has
been added to handle reentrant calls in a <code>Rc&lt;RefCell&gt;</code>-based
solution.</p>
<p>Some example deployment scenarios:</p>
<ul>
<li>
<p>When the workload can be comfortably handled by a single core,
<strong>Stakker</strong> works more efficiently than a multi-threaded runtime
because there are no synchronization costs.  This fits the
traditional efficient &quot;main thread&quot; select/epoll non-blocking I/O
model used by many internet servers and GUI applications.</p>
</li>
<li>
<p>When the event-driven workload requires more than one core, several
<strong>Stakker</strong> instances (each with their associated actors) may be
run, on different cores and/or on different machines.  Workload must
then be distributed between them at a higher level using sharding or
some other form of load balancing.</p>
</li>
<li>
<p>In both cases when there is heavy processing to do, then that
processing could be offloaded to a threadpool.  In this case the
synchronization costs are small compared to the saving in processing
costs in the event-driven thread, and typically there will be no
contention with other threads as the background processing runs.</p>
</li>
</ul>
<p>Essentially if you're going to scale beyond one machine, you're going
to have to solve the problem of work distribution between processing
units anyway.  So you might as well make your processing units run as
fast as possible, which means running each of them on a single thread.
Using a certain amount of synchronization between a group of
independently-running threads is fine, for example to share common
immutable data, but it's best to think hard before introducing shared
mutable state between threads, or too much locking, or too much
inter-thread messaging.  By staying low-level, <strong>Stakker</strong> forces you
to think about that.  What is easy is fast, and what is slower takes
more effort.</p>
<p><strong>Stakker</strong>'s approach won't suit all applications, but that is fine.
There are other crates to handle the other scenarios.  <strong>Stakker</strong>
concentrates on being efficient within its own niche.</p>
<h1><a class="header" href="#why-single-threaded" id="why-single-threaded">Why single-threaded?</a></h1>
<p>Consider the levels of locality that different actor systems operate
over, along with the different restrictions on message contents for
each.  (Note that if actors are intended to migrate, then the
restrictions apply to actor state as well.)</p>
<p>Here are some levels with example types to illustrate this:</p>
<table><thead><tr><th align="left">Locality</th><th align="left">Message</th><th align="left">Actor ref</th><th align="left">Pass data by ref</th><th align="left">Share mutably</th></tr></thead><tbody>
<tr><td align="left">Thread</td><td align="left"><code>'static</code></td><td align="left"><code>Rc</code></td><td align="left"><code>Box</code> or <code>Vec</code></td><td align="left"><code>Rc&lt;Cell&gt;</code> or <a href="https://docs.rs/stakker/*/stakker/struct.Share.html"><code>Share</code></a></td></tr>
<tr><td align="left">Process</td><td align="left"><code>Send</code></td><td align="left"><code>Arc</code></td><td align="left"><code>Box</code> or <code>Vec</code> + <code>Send</code></td><td align="left"><code>Arc&lt;Mutex&gt;</code></td></tr>
<tr><td align="left">Distributed</td><td align="left">serializable</td><td align="left">ID</td><td align="left">n/a</td><td align="left">n/a</td></tr>
</tbody></table>
<p>(Note that <code>'static</code> means &quot;no active borrows to stuff that might go
away&quot;, which is just Rust's borrow checker making sure you don't crash
your process.)</p>
<p>If your whole actor system is going to have a uniform interface, you
need to pick your level, commit to it and optimise for it.  Doing half
of one and half of another might give some of the benefits of both,
but it also brings the restrictions of both.  This results in
implementations having to take &quot;opinionated&quot; positions.</p>
<p>For a multi-threaded actor runtime, you pay the cost of
synchronization and then must hope that maxing out as many cores as
possible makes up for those costs in the application area of interest.
For a distributed actor runtime, you accept the limitations and costs
of everything being serializable in order to gain the benefit of
distributed execution.  However if we choose to limit ourselves to a
single thread, then we can avoid those restrictions entirely and stay
low-level and fast, free to use non-<code>Send</code> types and so on.</p>
<p><strong>Stakker</strong>'s design decisions means it naturally fits the
fully-committed single-thread approach, which it takes full advantage
of.  Allowing seamless migration of actors between threads and
redirection of queued calls to other threads would mean abandoning a
lot of the single-thread performance and distinctive features of
<strong>Stakker</strong>.  So for now <strong>Stakker</strong> concentrates on the low-level
goal of fast operation within a single thread.</p>
<p>Maybe in the future it might be possible to add some kind of a
distributed or inter-thread message-passing layer above existing
<strong>Stakker</strong> actors.  There are some questions, though:</p>
<ul>
<li>What kind of application scenario are we targetting?</li>
<li>Should we enable actors to migrate?  To other threads?  To other
machines?</li>
<li>Should there be proxy actors to redirect calls, or some kind of
direct message-sending mechanism?</li>
<li>How can we protect local same-thread calls from these overheads?</li>
<li>How should we represent references to actors that are on another
thread or another machine?  With the existing actor-reference types
and proxies, or with new types?</li>
</ul>
<p>There's not just the question of whether it can be done (which
obviously it can), but whether it can be done efficiently, and whether
the ergonomics can be made natural and comfortable for the coder.</p>
<p>This might be an interesting thing to investigate at some point.</p>
<h1><a class="header" href="#timer-queue" id="timer-queue">Timer queue</a></h1>
<p>The timer queue contains a list of <a href="https://doc.rust-lang.org/stable/std/ops/trait.FnOnce.html"><code>FnOnce</code></a> calls to execute at
specific instants.  What we need from this queue is:</p>
<ul>
<li>To give us the next expiry time</li>
<li>To execute items from the front of the queue when time advances</li>
<li>To add and delete items</li>
</ul>
<p>A <a href="https://doc.rust-lang.org/stable/std/collections/struct.BinaryHeap.html"><code>BinaryHeap</code></a> might be good for this queue, except for the problem
of deletions being O(N).  So instead for the moment a <a href="https://doc.rust-lang.org/stable/std/collections/struct.BTreeMap.html"><code>BTreeMap</code></a> is
used.  The map is partitioned to split off the items to execute when
time advances.  This should scale much better than a binary heap,
especially considering deletions.  However a <a href="https://doc.rust-lang.org/stable/std/collections/struct.BTreeMap.html"><code>BTreeMap</code></a> generates a
lot of code, so it is likely a combined N-ary heap tuned to cache line
size and <code>Vec</code> to support deletion might perform better.  So the
underlying implementation will probably change at some point, once
various scenarios have been benchmarked.</p>
<p>Apart from fixed timers, there are also &quot;max&quot; and &quot;min&quot; timers, that
can be adjusted very cheaply (just a memory write), without having to
add and delete timers from the timer queue most of the time.</p>
<p>For fixed timers, the <a href="https://doc.rust-lang.org/stable/std/collections/struct.BTreeMap.html"><code>BTreeMap</code></a> maps a 64-bit key (32-bit wrapping
expiry time + 31-bit unique value) to a boxed <a href="https://doc.rust-lang.org/stable/std/ops/trait.FnOnce.html"><code>FnOnce</code></a>.  For min/max
timers, the 64-bit key in the map consists of a 32-bit provisional
expiry time and a 31-bit slot number.  The actual current expiry time
which is updated by the calls is kept in a separate array.  When the
timer expires, the current expiry time is checked, and another timer
added back in if necessary.</p>
<h1><a class="header" href="#deferrer" id="deferrer">Deferrer</a></h1>
<p>A <a href="https://docs.rs/stakker/*/stakker/struct.Deferrer.html"><code>Deferrer</code></a> is an object that allows a call to be submitted to the
main queue.  Mostly the coder does not need to worry about this,
because there are ways to submit a call from almost everywhere:</p>
<ul>
<li>
<p>In all actor calls, there is the <code>cx</code> context available, which
allows calls to be submitted directly to the runtime</p>
</li>
<li>
<p>Each actor reference has access to a <a href="https://docs.rs/stakker/*/stakker/struct.Deferrer.html"><code>Deferrer</code></a> kept in the
actor's external data, which means that it is always possible to
submit a call if you have an <a href="https://docs.rs/stakker/*/stakker/struct.Actor.html"><code>Actor</code></a> or <a href="https://docs.rs/stakker/*/stakker/struct.ActorOwn.html"><code>ActorOwn</code></a> reference.</p>
</li>
</ul>
<p>However in the case that you need to submit a call from a drop
handler, and that drop handler does not have any actor references
available, you may need to obtain a <a href="https://docs.rs/stakker/*/stakker/struct.Deferrer.html"><code>Deferrer</code></a> and store it in the
struct that will be dropped.</p>
<p>Note that a <a href="https://docs.rs/stakker/*/stakker/struct.Deferrer.html"><code>Deferrer</code></a> takes zero bytes unless either the crate
feature &quot;multi-stakker&quot; or &quot;inline-deferrer&quot; is enabled.  This is
because if there is only ever a single <a href="https://docs.rs/stakker/*/stakker/struct.Stakker.html"><code>Stakker</code></a> instance running in
the whole process (or thread), we can optimise a <a href="https://docs.rs/stakker/*/stakker/struct.Deferrer.html"><code>Deferrer</code></a> to use a
global variable (or thread-local).  Only in the case of needing
multiple <a href="https://docs.rs/stakker/*/stakker/struct.Stakker.html"><code>Stakker</code></a> instances in a single thread (a much rarer case)
does the <a href="https://docs.rs/stakker/*/stakker/struct.Deferrer.html"><code>Deferrer</code></a> need to be a direct reference, in which case it
consumes one <code>usize</code>.  So you don't pay the cost unless you need it.</p>
<h1><a class="header" href="#actor-prep-state" id="actor-prep-state">Actor <strong>Prep</strong> state</a></h1>
<p>An actor may be in one of three states: <strong>Prep</strong>, <strong>Ready</strong> and
<strong>Zombie</strong>.  The purpose of the <strong>Prep</strong> state is to allow time for an
actor to set itself up before accepting calls.  Actors are created
instantaneously, but the initialisation call is made asynchronously,
so for even the simplest actor, there will be some time where the
actor is in the <strong>Prep</strong> state.</p>
<p>Since actor initialisation is asynchronous and has no time bound, the
actor may do quite complex operations in the <strong>Prep</strong> state, for
example attempting to make a connection to a remote server, or calling
and receiving responses back from other actors.  In this case
remaining in the <strong>Prep</strong> state means that the actor is signalling to
the runtime that it is &quot;not yet ready&quot; to accept normal actor calls.</p>
<p>Any actor calls made to it are queued until it enters the <strong>Ready</strong>
state.  This simplifies the logic of actors since otherwise the actor
would be forced to do its own queuing of requests if it was not yet
ready to service them.</p>
<p>To support doing asynchronous calls to other actors in the <strong>Prep</strong>
state, it's possible to create <a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> and <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> instances that call
back to <strong>Prep</strong> state methods instead of normal actor methods.</p>
<h1><a class="header" href="#signatures-of-actor-methods" id="signatures-of-actor-methods">Signatures of actor methods</a></h1>
<p>Methods that handle calls made to an actor in the <strong>Ready</strong> state have
the following signature, where &quot;...args...&quot; indicates 0 or
more additional arguments:</p>
<pre><code class="language-rust no_run noplayground">fn method(&amp;mut self, cx: CX![], ...args...) {...}
</code></pre>
<p>A <code>&amp;mut self</code> or <code>&amp;self</code> argument gives access to the actor state, and
<code>cx</code> gives access to the runtime via the <a href="https://docs.rs/stakker/*/stakker/struct.Cx.html"><code>Cx</code></a> type.  Methods that
handle calls in the <strong>Prep</strong> state use the following signature:</p>
<pre><code class="language-rust no_run noplayground">fn method(cx: CX![], ...args...) -&gt; Option&lt;Self&gt; {...}
</code></pre>
<p>These do not have a <code>self</code> argument because in the <strong>Prep</strong> state the
actor does not yet have a <code>Self</code> value as it is not yet initialised.
If the <strong>Prep</strong> method is ready to put the actor into the <strong>Ready</strong>
state and start handling normal actor calls, it should return a <code>Self</code>
value as <code>Some(...)</code>.  If it is not yet ready then it should return
<code>None</code> and make sure that some external callback or timer is active
that will guarantee that another <strong>Prep</strong> method will run in due
course, to continue with the preparation of the actor, or to
initialise it, or to terminate it with a failure.</p>
<p>Note that methods with any other signature to the ones above are not
callable through the actor system.  Normal Rust visibility rules apply
to the methods, so if these calls need to be accessed outside of the
module, they should be marked as <code>pub</code>, <code>pub(super)</code>, etc as
necessary.</p>
<h1><a class="header" href="#alternatives-to-the-actor-method-signature" id="alternatives-to-the-actor-method-signature">Alternatives to the actor method signature</a></h1>
<p>An actor method in <strong>Stakker</strong> has this signature:</p>
<pre><code class="language-rust no_run noplayground">fn method(&amp;mut self, cx: CX![], ...args...) {...}
</code></pre>
<p>There are four things that need to be passed into an actor method:</p>
<ul>
<li>A <code>&amp;mut self</code> reference, to allow direct access to the actor's state</li>
<li>A context to allow stopping and failing the actor and getting an
<code>Actor&lt;Self&gt;</code> reference</li>
<li>A reference to the runtime to allow adding timers, deferring calls
and to support borrowing <code>Share</code> instances and so on</li>
<li>The arguments to the call</li>
</ul>
<p>So this is handled as <code>(&amp;mut self, cx: CX![], ...args...)</code>, where <code>cx</code>
gives access to both the actor's specific context <a href="https://docs.rs/stakker/*/stakker/struct.Cx.html"><code>Cx</code></a> and by
auto-deref to the runtime <a href="https://docs.rs/stakker/*/stakker/struct.Core.html"><code>Core</code></a>.  Note that <code>cx: CX![]</code> is used to
avoid boilerplate and expands to <code>cx: &amp;mut Cx&lt;'_, Self&gt;</code>.</p>
<p>However, some alternative approaches were considered:</p>
<ul>
<li>
<p>Pass just <code>(&amp;mut self, ...args...)</code> and include <code>cx</code> in <code>Self</code> as
<code>self.cx</code>.  This means storing an extra 8 bytes in every actor
struct, wasting memory and forcing a write to memory just for the
short time that <code>Cx</code> is required during a call.  This seems like a
bad idea.</p>
</li>
<li>
<p>Require the coder to put actor methods into separate <code>impl Prep&lt;MyActor&gt; {...}</code> and <code>impl Ready&lt;MyActor&gt; {...}</code> sections, where
the <code>Ready</code> wrapper is effectively <code>(&amp;mut MyActor, &amp;mut Cx&lt;MyActor&gt;)</code>.  If the method self argument is <code>mut self</code> or <code>&amp;mut self</code> then it can be made to auto-deref to <code>&amp;mut MyActor</code> so that
the actor state is directly accessible through <code>self</code> as normal, and
also offer access to the other functions of <code>Cx</code> through for example
<code>self.stop()</code> or <code>self.core</code>.</p>
<p>The most immediate problem with this is that Rust currently does not
permit that <code>impl</code> when <code>Ready</code> and <code>MyActor</code> are in different
crates, with the error &quot;cannot define inherent <code>impl</code> for a type
outside of the crate where the type is defined&quot;.  I could find no
workaround for this that didn't bring along its own issues.</p>
<p>This approach gives shorter argument lists and conveniently
separates <em>Prep</em>, <em>Ready</em>, and instance methods (making the actor
API clearer), at the cost of having two <code>impl</code> sections, and a
possible additional overhead for accessing actor state.  Also it is
less obvious what is happening behind the scenes, since <code>self</code> is
overloaded for two (or three) different purposes.</p>
</li>
<li>
<p>Using procedural macros, it would be possible to write the calls any
way we want, and transform them into the right form for the
compiler.  However <strong>Stakker</strong> intentionally avoids this kind of
thing because it is not transparent, i.e. the coder can't see what
is going on.  Procedural macros in general can generate a huge
amount of code behind the scenes without the coder realizing.
Really you're no longer writing Rust in this case.  So the
preference is to keep things explicit and transparent, and use
macros only for small regions, where they are necessary to keep
things clear, and not to wrap large regions of code.</p>
</li>
</ul>
<p>So, the <code>cx: CX![]</code> approach is kept because it is more explicit,
low-level and unabstracted.  Everything is exactly what you see:
<code>Self</code> access is direct, and <code>self</code> and <code>cx</code> can be used independently
as necessary.  It's more Rust's style to make things explicit in the
code.</p>
<h1><a class="header" href="#data-kept-alongside-the-actor-internal-state" id="data-kept-alongside-the-actor-internal-state">Data kept alongside the actor internal state</a></h1>
<p>Due to the borrowing approach, the actor state is split into two parts.
The first part is outside the actor cell, and is accessible to any
runtime call that has an actor reference:</p>
<ul>
<li>Weak reference count</li>
<li>Strong reference count</li>
<li>Actor state: <strong>Prep</strong>, <strong>Ready</strong>, <strong>Zombie</strong></li>
<li>Termination notifier <code>Ret&lt;StopCause&gt;</code></li>
<li>A <a href="https://docs.rs/stakker/*/stakker/struct.Deferrer.html"><code>Deferrer</code></a> instance</li>
</ul>
<p>The <a href="https://docs.rs/stakker/*/stakker/struct.Deferrer.html"><code>Deferrer</code></a> is required in order to support dropping the last
<a href="https://docs.rs/stakker/*/stakker/struct.ActorOwn.html"><code>ActorOwn</code></a>.  It is also used for <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> and <a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> instances
calling the actor, and to support <a href="https://docs.rs/stakker/*/stakker/macro.call.html"><code>call!</code></a> when only the actor is
mentioned.  It also means that any drop handler that has access to an
actor reference also has a <a href="https://docs.rs/stakker/*/stakker/struct.Deferrer.html"><code>Deferrer</code></a> available.</p>
<p>Note that <a href="https://doc.rust-lang.org/stable/std/rc/struct.Rc.html"><code>Rc</code></a> is not used to handle the weak and strong references,
because we need to keep some data outside the cell that is accessible
to a weak reference even if the strong reference count has gone to
zero.  Also we need to be able to terminate the actor even when there
are still strong references.</p>
<p>The second part is inside the actor cell, and so is only accessible
when there is a <code>&amp;mut Stakker</code> reference available.  So this is not
accessible within calls to other actors, where the <code>&amp;mut Stakker</code>
reference is occupied by the borrow that enables access to the actor
cell for that call.  The actor cell contains:</p>
<ul>
<li>For <strong>Prep</strong>: <a href="https://doc.rust-lang.org/stable/std/ops/trait.FnOnce.html"><code>FnOnce</code></a> queue to store calls attempted before the actor
is <strong>Ready</strong></li>
<li>For <strong>Ready</strong>: <code>Self</code> value for the actor</li>
</ul>
<h1><a class="header" href="#overhead-of-an-actor" id="overhead-of-an-actor">Overhead of an actor</a></h1>
<p>With default features on a 64-bit platform, an actor requires one
allocation of 48 + <code>Self</code> bytes for the actor, and a second allocation
of 8 bytes for the termination notifier.  The details follow:</p>
<p>The table below shows the sizes requested from <code>malloc</code>, so include
the internal data used by the reference-counting implementation.</p>
<table><thead><tr><th align="center">Features</th><th align="center">1000-byte actor</th><th align="center">Overhead</th><th align="center">Notifier</th><th align="center">0-byte actor</th></tr></thead><tbody>
<tr><td align="center">default</td><td align="center">1048</td><td align="center">48</td><td align="center">8</td><td align="center">72</td></tr>
<tr><td align="center">no-unsafe</td><td align="center">1056</td><td align="center">56</td><td align="center">8</td><td align="center">80</td></tr>
<tr><td align="center">all features</td><td align="center">1080</td><td align="center">80</td><td align="center">8</td><td align="center">104</td></tr>
</tbody></table>
<p>The Overhead column shows the bytes used above the actor's own
<code>Self</code> instance size.</p>
<p>The Notifier column shows the bytes required for a simple <a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a>
instance created using <a href="https://docs.rs/stakker/*/stakker/macro.ret_to.html"><code>ret_to!</code></a> to notify a parent of the
termination of this actor.  This is a separate allocation because it
is variable-sized in general.  Note that the Notifier overhead is
optional, as you can use <a href="https://docs.rs/stakker/*/stakker/macro.ret_nop.html"><code>ret_nop!</code></a> which avoids that allocation,
but normally it will be required.</p>
<p>Regarding the 0-byte actor column: The actor's <code>Self</code> structure is in
a union with a <a href="https://doc.rust-lang.org/stable/std/ops/trait.FnOnce.html"><code>FnOnce</code></a> queue, so <code>Self</code> structures smaller than 24
bytes still consume the minimum 24 bytes.</p>
<h1><a class="header" href="#design-of-macro-argument-structure" id="design-of-macro-argument-structure">Design of macro argument structure</a></h1>
<p>The design of the macro argument structure, e.g. for <a href="https://docs.rs/stakker/*/stakker/macro.call.html"><code>call!</code></a> or
<a href="https://docs.rs/stakker/*/stakker/macro.fwd_to.html"><code>fwd_to!</code></a> required several attempts before the syntax felt
comfortable.  One aim was for the syntax within the macro call to be
valid if interpreted as Rust syntax so that <code>rustfmt</code> would format it
automatically.  Another was for the structure to be reasonably
intuitive to understand without having to constantly refer back to
documentation.  It is much too easy to end up with a list of anonymous
fields to fill in, or confusing arguments that appear in some places
but not others.</p>
<p>So to give it more structure, the destination being addressed was put
in brackets, for example <code>[cx]</code> or <code>[self.other_actor]</code> or <code>[fwd]</code>,
and things were made to look like actual methods being called as far
as possible.</p>
<p>For <a href="https://docs.rs/stakker/*/stakker/macro.fwd_to.html"><code>fwd_to!</code></a>, it ends up looking something like currying, with the
constant arguments given first, and the variable argument types
following in a tuple after <code>as</code>, which is also valid Rust syntax to
introduce a type, encouraging IDEs to help with type completion if
they support that.</p>
<p>Another aspect of the macros is that a lot of tuning was done on the
order of evaluation of the arguments.  Whereas in plain Rust code,
you'd often get a borrow-checker error due to mentioning the same
variable more than once, in the macro you will often find that you can
get away with it due to the macro's internal order of evaluation.  All
arguments are evaluated in the caller's context before the call is
deferred, to keep the code intelligible.</p>
<h1><a class="header" href="#dropping-things-to-clean-up" id="dropping-things-to-clean-up">Dropping things to clean up</a></h1>
<p><strong>Stakker</strong> maintains the Rust convention of easy clean-up by simply
dropping things.  If dropping something in the <strong>Stakker</strong> API doesn't
clean things up correctly, then that is probably a bug.</p>
<p>So for example if you drop the last <a href="https://docs.rs/stakker/*/stakker/struct.ActorOwn.html"><code>ActorOwn</code></a> referring to an
actor, then the actor will be terminated and the actor's drop handler
called.  Or if you drop a <a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> instance, then <code>None</code> is sent back,
which indicates that the message containing the <a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> wasn't replied
to.  Or if you drop a <a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a> in another thread, the wake handler is
informed and the slot released.</p>
<p>The intention is that if you keep to certain simple conventions, then
you can rely on drop-based cleanup to take care of all problem
situations.  For example if you use <a href="https://docs.rs/stakker/*/stakker/struct.ActorOwn.html"><code>ActorOwn</code></a> links in a DAG
(e.g. a tree of actors with parents and children), then when one actor
fails, the whole tree of actors that it owns will also be cleaned up
correctly.  This also means that if anything goes wrong in an actor,
then calling <a href="https://docs.rs/stakker/*/stakker/struct.Cx.html#method.fail"><code>fail</code></a> or <a href="https://docs.rs/stakker/*/stakker/struct.Cx.html#method.fail_str"><code>fail_str</code></a> should always be a safe way to
bail out.  The actor and all its children will clean up, and the parent
actor will be informed of the failure.</p>
<p>However, if you decide to try and implement some more complicated form
of inter-actor ownership that isn't a DAG, perhaps with <a href="https://docs.rs/stakker/*/stakker/struct.ActorOwn.html"><code>ActorOwn</code></a>
loops and manual <a href="https://docs.rs/stakker/*/stakker/struct.Actor.html#method.kill"><code>kill</code></a> calls to do cleanup, then it's your
responsibility to make sure that clean-up occurs correctly in all
failure modes.</p>
<p>Another issue occurs when your actor allocates internal resources to
service another actor's request, and you wish to know if that actor
fails in order to release those resources.  This can be solved by
creating a droppable &quot;guard&quot; object which is passed to the associated
actor for it to store.  If the actor dies, then the drop handler of
your guard runs, which can send a message back to your actor to clean
up, via an <a href="https://docs.rs/stakker/*/stakker/struct.Actor.html"><code>Actor</code></a> reference to your actor that it holds.</p>
<h1><a class="header" href="#cargo-features-and-safety" id="cargo-features-and-safety">Cargo features and safety</a></h1>
<p>By default <strong>Stakker</strong> uses some <code>unsafe</code> for efficiency.  This means
it uses implementations that require less memory or less CPU time.
However, if you wish, you can enable the &quot;no-unsafe&quot; Cargo feature,
and the whole crate will be compiled with <code>#[forbid(unsafe_code)]</code>,
and fully safe implementations are used instead.  You lose some
efficiency, but for many applications that would make little
difference, so use this if minimising <code>unsafe</code> is important for your
project.</p>
<p>There are other cargo features that switch in and out different
underlying implementations to optimise for different cases.  However
the external API of the crate does not change when features are
changed.  The API should operate identically.</p>
<p>Note that since Cargo features are additive, it's necessary that when
more than one crate in a build uses <strong>Stakker</strong>, the <strong>Stakker</strong> build
should be compatible with all of them, i.e. provide the lowest common
denominator.  So this typically means using the less optimal
implementation.</p>
<p>Note that crates should not enable <strong>Stakker</strong> cargo features unless
they really need them.  It should be up to the top-level application
to add features as required.  Note that even if the top-level
application does not use <strong>Stakker</strong> directly, it is still possible to
list the crate as a dependency in order to select cargo features.</p>
<h1><a class="header" href="#why-use-actors" id="why-use-actors">Why use actors?</a></h1>
<p>If you find that your code has to accept events from more than one
direction, and has to react correctly to each event based on the
current state, and has to deal with a lot more variations than a
&quot;happy path, or fail&quot;, then actors provide a convenient way to manage
that complexity.  There is a reason why a lot of networking is based
around state machines!  An actor is essentially the implementation of
a state machine and the transitions between those states in response
to events.</p>
<p>In addition, dividing a larger problem into a set of asynchronously
interacting actors means that each small part of the problem can be
analysed and understood clearly in isolation, and tested
asynchronously independently of the rest of the system.</p>
<p>Also, the abstraction provided by actors naturally allows interacting
actors to be separated and run remotely if necessary.  Since
inter-actor calls are asynchronous, no actor can depend on synchronous
responses, so distributed and remote operation comes naturally.  The
only thing required is some glue to pass the inter-actor calls over a
protocol.</p>
<p>However for a long sequence of asynchronous operations that either
advance to the next or fail, a sequential &quot;actor coroutine&quot; style
might make the code clearer than an event-driven actor style.  So
adding async/await or generators on top of the actors, to provide
something like a coroutine that can be driven forward by actor events
is a possible future direction for <strong>Stakker</strong>, if it can be made
efficient.</p>
<h1><a class="header" href="#stakker-guide" id="stakker-guide">Stakker Guide</a></h1>
<p>This section provides more practical information on coding with
<strong>Stakker</strong>.</p>
<h1><a class="header" href="#finding-stakker-compatible-crates" id="finding-stakker-compatible-crates">Finding <strong>Stakker</strong>-compatible crates</a></h1>
<p>Here are some considerations to help decide whether a crate is usable
with <strong>Stakker</strong>:</p>
<ul>
<li>
<p><strong>Non-blocking:</strong> If it is going to be called directly from an
actor, the crate must never block or sleep, because that would hold
up all the work of the whole thread.</p>
</li>
<li>
<p><strong>Data processing only:</strong> If it just does data processing when
called, and doesn't require any I/O or timers or anything, then that
would be straightforward to use.  (For example <a href="https://crates.io/crates/regex"><strong>regex</strong></a> crate.)</p>
</li>
<li>
<p><strong>Event-loop independent:</strong> If it requires I/O but says it can run
on top of any event loop, then that is a very good sign.  Even
crates that may appear dependent on a particular I/O system (<code>mio</code>,
Tokio, etc) might still be usable if the protocol handling can be
called independently.  (For example <a href="https://crates.io/crates/tungstenite"><strong>tungstenite</strong></a>)</p>
</li>
<li>
<p><strong>Event-loop providers:</strong> If a crate provides an event loop (or the
basis for an event loop), for example SDL or <code>mio</code>, then <strong>Stakker</strong>
can almost certainly be run on top of it, so long as the underlying
crate can guarantee that <strong>Stakker</strong> is always called from the same
thread.</p>
</li>
</ul>
<p>Where a required crate can't be run on top of <strong>Stakker</strong>, for example
a crate that depends on Tokio, then you can still run it in the same
process by running Tokio in another thread and communicating with the
<strong>Stakker</strong> thread via channels.</p>
<p>A possible future extension to <strong>Stakker</strong> would be to add a simple
async/await executor, one that allows a subset of async/await crates
to run, for example ones that can process futures or streams passed
from the actor runtime, and that don't require direct I/O themselves.</p>
<h1><a class="header" href="#difference-between-ret-and-fwd" id="difference-between-ret-and-fwd">Difference between <code>Ret</code> and <code>Fwd</code></a></h1>
<p>Both of these types allow specifying a callback or call-forward,
usually to an actor method but possibly to some other destination.
But there are some important differences:</p>
<ul>
<li><a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> can be called only once, and <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> may be called many
times</li>
<li><a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> cannot be cloned, but <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> has ref-counting and there may
be many references to the same <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> callback</li>
<li><a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> can capture &quot;move&quot; types</li>
<li><a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> is consumed when it is called</li>
<li><a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> notifies the callback if it is dropped without being called</li>
</ul>
<p>Whilst the names suggest uses of returning or forwarding data, there
are no restrictions about where the data is sent.  So a <a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> may
'return' data back to some other actor than the caller if required.</p>
<h1><a class="header" href="#detecting-delivery-failure-using-ret" id="detecting-delivery-failure-using-ret">Detecting delivery failure using <code>Ret</code></a></h1>
<p>A <a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> callback is guaranteed to always be called eventually, even if
it is lost and dropped.  So this means that if a call is made to an
actor that terminates before the call is serviced, any <a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> included
in the arguments to that call will be dropped and a <code>None</code> response
will be sent back.</p>
<p>So this means that any call where there needs to be an action if the
message cannot be handled needs to include a <a href="https://docs.rs/stakker/*/stakker/struct.Ret.html"><code>Ret</code></a> in its arguments,
even if it is just a <code>Ret&lt;()&gt;</code> which is called with no arguments on
successfully processing the call.  The <a href="https://docs.rs/stakker/*/stakker/macro.ret_to.html"><code>ret_to!</code></a> macro supports this
scenario.</p>
<p>However where it is not important to handle the case where the call is
lost, the <a href="https://docs.rs/stakker/*/stakker/macro.ret_some_to.html"><code>ret_some_to!</code></a> macro unwraps the value and ignores the
<code>None</code> (dropped) case.</p>
<h1><a class="header" href="#handling-expected-and-unexpected-actor-termination" id="handling-expected-and-unexpected-actor-termination">Handling expected and unexpected actor termination</a></h1>
<p>There are five ways that an actor can terminate.  These are
enumerated by the <a href="https://docs.rs/stakker/*/stakker/enum.StopCause.html"><code>StopCause</code></a> enum:</p>
<ul>
<li><code>Stopped</code>: Successful termination</li>
<li><code>Failed</code>: Actor terminated itself due to some problem</li>
<li><code>Killed</code>: Actor was killed by another entity</li>
<li><code>Dropped</code>: The last <a href="https://docs.rs/stakker/*/stakker/struct.ActorOwn.html"><code>ActorOwn</code></a> referencing this actor was dropped</li>
<li><code>Lost</code>: This indicates that the connection to a remote actor has
been lost.  Remote actors are not implemented yet.</li>
</ul>
<p>Both <code>Failed</code> and <code>Killed</code> have an associated boxed <a href="https://doc.rust-lang.org/stable/std/error/trait.Error.html"><code>Error</code></a>.  When
an actor is created, a notification handler <code>Ret&lt;StopCause&gt;</code> is
normally provided.  This receives the reason for the actor's
termination when it terminates.  So usually a parent actor will keep a
hold of the <a href="https://docs.rs/stakker/*/stakker/struct.ActorOwn.html"><code>ActorOwn</code></a> for the child actor within its own state, and
will receive the termination notification.  However other patterns are
also possible.</p>
<p>On receiving a termination notification, the parent actor might choose
to restart the child, or terminate itself, or take some other action.
The parent actor has a free choice on how to handle it.  It is
possible to downcast the <a href="https://doc.rust-lang.org/stable/std/error/trait.Error.html"><code>Error</code></a> to take a different action
depending on the type of failure if necessary.</p>
<h1><a class="header" href="#actordyn-trait" id="actordyn-trait"><code>Actor&lt;dyn Trait&gt;</code></a></h1>
<p>If you need to have a group of different actors that all implement the
same interface and that can be used interchangeably behind that
standard interface, there are several options available.  However
<code>Actor&lt;dyn Trait&gt;</code> is not one of them, for reasons that will be
explained below!</p>
<h2><a class="header" href="#use-a-trait-on-the-actor-side-actorboxdyn-trait" id="use-a-trait-on-the-actor-side-actorboxdyn-trait">Use a trait on the actor side: <code>Actor&lt;Box&lt;dyn Trait&gt;&gt;</code></a></h2>
<p>There is a macro <a href="https://docs.rs/stakker/*/stakker/macro.actor_of_trait.html"><code>actor_of_trait!</code></a> to support this.  This all looks
clean and minimal in the source.  On the caller side, all they see is
a standard-looking actor interface.  However compared to a non-trait
actor, this adds an extra indirection to all calls due to the <code>Box</code>.
Here's an example:</p>
<pre><code class="language-rust no_run noplayground">use stakker::*;
use std::time::Instant;

// Trait definition
type Animal = Box&lt;dyn AnimalTrait&gt;;
trait AnimalTrait {
    fn sound(&amp;mut self, cx: CX![Animal]);
}

struct Cat;
impl Cat {
    fn init(_: CX![Animal]) -&gt; Option&lt;Animal&gt; {
        Some(Box::new(Cat))
    }
}
impl AnimalTrait for Cat {
    fn sound(&amp;self, _: CX![Animal]) {
        println!(&quot;Miaow&quot;);
    }
}

struct Dog;
impl Dog {
    fn init(_: CX![Animal]) -&gt; Option&lt;Animal&gt; {
        Some(Box::new(Dog))
    }
}
impl AnimalTrait for Dog {
    fn sound(&amp;mut self, _: CX![Animal]) {
        println!(&quot;Woof&quot;);
    }
}

pub fn main() {
    let mut stakker = Stakker::new(Instant::now());
    let s = &amp;mut stakker;

    let animal1 = actor_of_trait!(s, Animal, Cat::init(), ret_nop!());
    let animal2 = actor_of_trait!(s, Animal, Dog::init(), ret_nop!());

    let mut list: Vec&lt;Actor&lt;Animal&gt;&gt; = Vec::new();
    list.push(animal1.clone());
    list.push(animal2.clone());

    for a in list {
        call!([a], sound());
    }
    s.run(Instant::now(), false);
}
</code></pre>
<h2><a class="header" href="#use-a-trait-on-the-caller-side-boxdyn-trait" id="use-a-trait-on-the-caller-side-boxdyn-trait">Use a trait on the caller side: <code>Box&lt;dyn Trait&gt;</code></a></h2>
<p>This involves wrapping the actors in a trait that forwards calls, and
then boxing it to make it dynamic.  So this also adds an indirection,
but on the caller side.  This is more verbose than doing it on the
actor side, and the calls don't look like other actor calls.  Here's
an example:</p>
<pre><code class="language-rust no_run noplayground">use stakker::*;
use std::time::Instant;

// External interface of all Animals
trait Animal {
    fn sound(&amp;self);
}

// A particular animal, wraps any actor that implements AnimalActor
struct AnAnimal&lt;T: AnimalActor + 'static&gt;(ActorOwn&lt;T&gt;);
impl&lt;T: AnimalActor + 'static&gt; Animal for AnAnimal&lt;T&gt; {
    fn sound(&amp;self) {
        call!([self.0], sound());
    }
}

// Internal interface of animal actors
trait AnimalActor: Sized {
    fn sound(&amp;self, cx: CX![]);
}

struct Cat;
impl Cat {
    fn init(_: CX![]) -&gt; Option&lt;Self&gt; {
        Some(Self)
    }
}
impl AnimalActor for Cat {
    fn sound(&amp;self, _: CX![]) {
        println!(&quot;Miaow&quot;);
    }
}

struct Dog;
impl Dog {
    fn init(_: CX![]) -&gt; Option&lt;Self&gt; {
        Some(Self)
    }
}
impl AnimalActor for Dog {
    fn sound(&amp;self, _: CX![]) {
        println!(&quot;Woof&quot;);
    }
}

fn main() {
    let mut stakker = Stakker::new(Instant::now());
    let s = &amp;mut stakker;

    let animal1 = AnAnimal(actor!(s, Dog::init(), ret_nop!()));
    let animal2 = AnAnimal(actor!(s, Cat::init(), ret_nop!()));

    let mut list: Vec&lt;Box&lt;dyn Animal&gt;&gt; = Vec::new();
    list.push(Box::new(animal1)); // &lt;- dyn coercion occurs here
    list.push(Box::new(animal2)); // &lt;- dyn coercion occurs here

    for a in list {
        a.sound();
    }
    s.run(Instant::now(), false);
}
</code></pre>
<h2><a class="header" href="#use-a-hrefhttpsdocsrsstakkerstakkerstructfwdhtmlfwda-and-a-hrefhttpsdocsrsstakkerstakkerstructactorownanonhtmlactorownanona" id="use-a-hrefhttpsdocsrsstakkerstakkerstructfwdhtmlfwda-and-a-hrefhttpsdocsrsstakkerstakkerstructactorownanonhtmlactorownanona">Use <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> and <a href="https://docs.rs/stakker/*/stakker/struct.ActorOwnAnon.html"><code>ActorOwnAnon</code></a></a></h2>
<p>Instead of using a trait, it's also possible to use <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> to capture
the entry point of an arbitrary actor, and to pass that to other
actors that only care about the forwarding interface.  The extra
indirection is also present in this solution, since the call must pass
via the <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> handler.  However this is a lot more flexible than
traits.</p>
<p>Where you want another actor to not only have a <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> instance but
also to hold the owning reference to the actor, then you can use
<a href="https://docs.rs/stakker/*/stakker/struct.ActorOwnAnon.html"><code>ActorOwnAnon</code></a>.  That way if that actor dies, the referenced actor
dies too.  This allows owning the actor without being exposed to the
type.  So you can keep a <code>Vec&lt;ActorOwnAnon&gt;</code> pointing to different
kinds of actors for example.</p>
<h2><a class="header" href="#why-actordyn-trait-cant-be-supported" id="why-actordyn-trait-cant-be-supported">Why <code>Actor&lt;dyn Trait&gt;</code> can't be supported</a></h2>
<p><code>Rc&lt;dyn Trait&gt;</code> can be done, so why isn't <code>Actor&lt;dyn Trait&gt;</code> possible?</p>
<p>To enable <code>dyn Trait</code> requires the actor runtime to be changed to use
<code>A: ?Sized</code>, where <code>A</code> is the actor's <code>Self</code> type.  Unfortunately Rust
does not support <code>?Sized</code> values inside an <code>enum</code>, apparently due to
it inhibiting layout optimisations, and <strong>Stakker</strong> requires an enum
to enable switching between the three actor states (<strong>Prep</strong>,
<strong>Ready</strong> and <strong>Zombie</strong>).  Maybe Rust could have a
<code>#[repr(unsizable)]</code> for enums to support this one day, but it doesn't
right now.</p>
<p>In addition <code>CoerceUnsized</code> is still unstable at the time of writing.
This is the approved way to do the &quot;dyn coercion&quot; which converts an
<code>Rc&lt;impl Trait&gt;</code> to an <code>Rc&lt;dyn Trait&gt;</code>.  However that can be worked
around, I believe.  So that isn't the blocker.</p>
<p>Looking at alternative approaches, it seemed like implementing a
custom <code>enum</code> in unsafe code might be possible using <code>union</code>, but that
is also a dead end due to <code>union</code> only supporting <code>Copy</code> types on
stable at present.  I have an <a href="https://crates.io/crates/unsized_enum"><strong>unsized_enum</strong></a> crate which I believe
is sound and could be the basis for <code>Actor&lt;dyn Trait&gt;</code> in <strong>Stakker</strong>,
but I don't want to force it on all <strong>Stakker</strong> users.  I'd like to be
able to offer a safe alternative as well.  (Update: As of Feb-2021
'union' supports <code>ManuallyDrop</code> which allows <code>?Sized</code>, so that might
offer a better way, although it still requires <code>unsafe</code>.)</p>
<p>So unfortunately it's not possible to do <code>Actor&lt;dyn Trait&gt;</code> right now,
and one of the alternatives must be used instead.</p>
<h1><a class="header" href="#top-level-actor-template" id="top-level-actor-template">Top-level actor template</a></h1>
<p>The following template may be helpful for writing big top-level actors
that need to accept configuration and need to be connected up to other
actors through <a href="https://docs.rs/stakker/*/stakker/struct.Fwd.html"><code>Fwd</code></a> instances.</p>
<pre><code class="language-rust no_run noplayground">/// `Widget` actor configuration.  Includes serde deserialization
/// support.
#[derive(Deserialize, Clone)]
#[serde(deny_unknown_fields)]
pub struct WidgetConf {
    // ... configuration values ...
}

/// `Widget` instance callbacks
pub struct WidgetFwds {
    // ... `Fwd` and `Share` values that the actor needs to talk to
    //   other actors and to access any shared resources ...
}

/// `Widget` actor
pub struct Widget {
    conf: WidgetConf,
    fwds: WidgetFwds,
    // ... actor state ...
}

impl Widget {
    /// Initialise the Widget actor
    pub fn init(cx: CX![], conf: WidgetConf, fwds: WidgetFwds) -&gt; Option&lt;Self&gt; {
       // ...
       Some(Self {
           conf,
           fwds,
           // ...
       })
    }

    //... all other actor methods ...
}
</code></pre>
<h1><a class="header" href="#inter-thread-communication-with-waker" id="inter-thread-communication-with-waker">Inter-thread communication with Waker</a></h1>
<p>The foundation for inter-thread communication in <strong>Stakker</strong> is the
<a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a> mechanism.  This uses an atomic bitmap-tree, which means
that many wakeup events from other threads will be accumulated into a
single I/O event on the <strong>Stakker</strong> thread, using only a small number
of atomic operations to recover them, keeping the load on the
<strong>Stakker</strong> thread low.</p>
<p>A <a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a> will normally be paired with a channel or some other
shared mutable state, e.g. data within a <code>Mutex</code>.  So the <a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a> is
used to notify a handler in the <strong>Stakker</strong> thread that it needs to
examine the shared state and respond to whatever it finds there.</p>
<p><a href="https://docs.rs/stakker/*/stakker/struct.PipedThread.html"><code>PipedThread</code></a> is an example of this, combining a thread, two message
pipes and a <a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a>.  This provides a convenient way to handle some
very simple scenarios for running heavy or blocking calls in another
thread.  However it should be straightforward to build other
inter-thread communication methods on top of <a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a>.</p>
<p>One thing to note is that when using channels such as <code>crossbeam</code>,
ideally we'd want to only notify the <a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a> when the channel is
empty at the instant that the message is added.  However the channel
APIs typically don't give us a way to detect this condition.  (Perhaps
it's not even possible to detect this in some cases due to how the
channel is implemented.)  Attempting to detect it with an <code>is_empty()</code>
call on the channel before adding the message is doomed to
intermittent failure due to races.  So this means that another thread
adding something to a channel for the <strong>Stakker</strong> thread to pick up
must notify the <a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a> on every message sent.  So <a href="https://docs.rs/stakker/*/stakker/struct.Waker.html"><code>Waker</code></a> is
designed to make this as cheap as possible.  After the first time, it
will take only one atomic operation.</p>
<h1><a class="header" href="#roadmap" id="roadmap">Roadmap</a></h1>
<p>Currently <strong>Stakker</strong> is performing well for the applications it is
being used in, so there is no urgent need for new features.  However
that does not mean it is &quot;done&quot;.  Things will be added gradually as
new requirements are discovered and refined.</p>
<p>Here are some near-term plans (6 months):</p>
<ul>
<li>
<p>More fully test running on top of a C++ language event loop within
another application, e.g. using <strong>Stakker</strong> in a library with a C++
interface</p>
</li>
<li>
<p>Benchmark timer-queue performance, and then optimise, e.g. changing
to an N-ary heap</p>
</li>
</ul>
<p>Waiting for new Rust language features:</p>
<ul>
<li>
<p>If Rust one day supports enums or unions containing a DST on one
variant (like an <code>Option&lt;dyn Trait&gt;</code> or a <code>MaybeUninit&lt;dyn Trait&gt;</code>),
then it would be possible to do <code>Actor&lt;dyn Trait&gt;</code> instead of
<code>Actor&lt;Box&lt;dyn Trait&gt;&gt;</code> as at present (see <a href="https://docs.rs/stakker/*/stakker/macro.actor_of_trait.html"><code>actor_of_trait!</code></a>).</p>
</li>
<li>
<p>If Rust had better support for working with VTables and fat
pointers, then a lot of unsafe code could be eliminated from the
flat FnOnceQueue.  See: https://github.com/rust-lang/rfcs/pull/2580</p>
</li>
<li>
<p>If Rust supported passing borrows and lifetimes into the generator
resume function, and generators were stabilized, then they could be
used to implement actor coroutines.  See:
https://github.com/rust-lang/rust/issues/68923</p>
</li>
</ul>
<p>Further ahead:</p>
<ul>
<li>
<p>Write more varied applications with <strong>Stakker</strong>, and see if that
suggests any more features that need adding.  If other people start
using <strong>Stakker</strong>, that may also suggest more features.</p>
</li>
<li>
<p>Maybe switch all macros over to procedural macros to allow <code>cx</code> to
be picked up automatically from the context, to make code more
concise.  (<code>macro_rules!</code> hygiene normally forbids this, but
procedural macros have different rules.)</p>
</li>
<li>
<p>Look at ways to proxy calls between actors on different threads or
different machines, i.e. where a local actor acts as a proxy for a
remote actor and forwards calls and responses</p>
</li>
<li>
<p>Investigate writing crates to allow Stakker to be layered on top of
other runtimes, e.g. <strong>tokio</strong> or <strong>async_std</strong>.</p>
</li>
<li>
<p>Investigate writing a simple async executor on top of <strong>Stakker</strong> to
interface directly to async/await style code in the same thread.
However if this is to be done at all it needs to be very low-level
and efficient, ideally avoiding any synchronisation, memory fences,
atomic operations, mutexes and so on.  Otherwise it might be better
to run one of the existing executors in another thread instead, and
communicate data with channels to keep the <strong>Stakker</strong> thread lean.</p>
</li>
<li>
<p>Possibly look at making use of generators or async/await to allow
writing sequential-style actor coroutines within an actor.  This
would allow making a call to another actor and receiving the <code>Ret</code>
directly in the code.  The main difficulty is passing the <code>Cx</code> (with
its lifetime) up into the coroutine at each resume, and having it
drop at each yield.  Because of the low-level nature of <strong>Stakker</strong>,
this needs to be efficient to be a good fit.  This will probably
require a good deal of experimentation and tweaking to find the
right ergonomics, and the best low-level fit.  There's no sense in
rushing it.</p>
</li>
<li>
<p>Support off-loading CPU-intensive or I/O work to a threadpool.  If
actor coroutines are implemented, then we could simply mark a block
of code as <code>offload!</code> to move it to a threadpool, which would be
very convenient.</p>
</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
